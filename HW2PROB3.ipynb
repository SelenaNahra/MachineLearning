{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+VyJWFFVtQwlxJKyeyFSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SelenaNahra/MachineLearning/blob/main/HW2PROB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_DshJxgO_VQ",
        "outputId": "443a7c2e-f2a0-44e7-f9e8-8f2793b441a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive and load the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/Housing.csv'\n",
        "housing = pd.read_csv(file_path)\n",
        "\n",
        "# List of variables to map\n",
        "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "# Defining the map function\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, 'no': 0})\n",
        "\n",
        "# Applying the function to the housing list\n",
        "housing[varlist] = housing[varlist].apply(binary_map)\n",
        "housing = housing.drop('furnishingstatus', axis=1)\n",
        "\n",
        "# We specify this so that the train and test data set always have the same rows, respectively\n",
        "np.random.seed(0)\n",
        "df_training, df_validation = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 100)\n",
        "\n",
        "normalized_training = df_training\n",
        "normalized_validation =  df_validation\n",
        "standardized_training = df_training\n",
        "standardized_validation =  df_validation\n",
        "\n",
        "# Normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "normalize = MinMaxScaler()\n",
        "normalized_training = normalize.fit_transform(normalized_training)\n",
        "normalized_validation = normalize.fit_transform(normalized_validation)\n",
        "normalized_training = pd.DataFrame(normalized_training, columns=df_training.columns)\n",
        "normalized_validation = pd.DataFrame(normalized_validation, columns=df_validation.columns)\n",
        "\n",
        "# Standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "standardize = StandardScaler()\n",
        "standardized_training = standardize.fit_transform(standardized_training)\n",
        "standardized_validation = standardize.fit_transform(standardized_validation)\n",
        "standardized_training = pd.DataFrame(standardized_training, columns=df_training.columns)\n",
        "standardized_validation = pd.DataFrame(standardized_validation, columns=df_validation.columns)\n",
        "\n",
        "# Extract output columns\n",
        "y_train = df_training.pop('price')\n",
        "y_valid = df_validation.pop('price')\n",
        "\n",
        "# Normalized outputs\n",
        "normalized_y_train = normalized_training.pop('price')\n",
        "normalized_y_valid = normalized_validation.pop('price')\n",
        "\n",
        "# Standardized outputs\n",
        "standardized_y_valid = standardized_training.pop('price')\n",
        "standardized_y_valid = standardized_validation.pop('price')\n",
        "\n",
        "def train(X, df_training, df_validation, y_train, y_valid, learning_rate, lambd, iterations):\n",
        "    training_inputs = df_training[X]\n",
        "    x_train = np.c_[np.ones((len(training_inputs), 1)), training_inputs]\n",
        "\n",
        "    val_inputs = df_validation[X]\n",
        "    x_val = np.c_[np.ones((len(val_inputs), 1)), val_inputs]\n",
        "\n",
        "    n = x_train.shape[1]\n",
        "    m_train = len(x_train)\n",
        "    m_valid = len(x_val)\n",
        "    theta = np.zeros(n)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for i in range(iterations):\n",
        "        h_theta = x_train.dot(theta)\n",
        "        error = np.subtract(h_theta, y_train)\n",
        "        gradient = (1 / m_train) * (x_train.transpose().dot(error))\n",
        "\n",
        "        theta = theta*(1 - learning_rate * (lambd / m_train)) - (learning_rate * gradient)\n",
        "\n",
        "        train_loss = 1 / (2 * m_train) * np.sum(np.square((h_theta - y_train)))\n",
        "        val_loss = 1 / (2 * m_valid) * np.sum(np.square((x_val.dot(theta) - y_valid)))\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Create data for 2.a\n",
        "X = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
        "learning_rate = 0.01\n",
        "lambd = 5\n",
        "iterations = 1000\n",
        "\n",
        "# Training with normalized inputs\n",
        "normalized_train_losses_a, normalized_valid_losses_a = train(X, normalized_training, normalized_validation, y_train, y_valid, learning_rate, lambd, iterations)\n",
        "\n",
        "# Training with standardized inputs\n",
        "standardized_train_losses_a, standardized_valid_losses_a = train(X, standardized_training, standardized_validation, y_train, y_valid, learning_rate, lambd, iterations)\n",
        "\n",
        "plt.plot(normalized_train_losses_a, label=\"Training Loss\")\n",
        "plt.plot(normalized_valid_losses_a, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"3a. Loss using Normalized Inputs\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(standardized_train_losses_a, label=\"Training Loss\")\n",
        "plt.plot(standardized_valid_losses_a, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"3a. Loss using Standardized Inputs\")\n",
        "plt.show()\n",
        "\n",
        "# Create data for 2.b\n",
        "X = ['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea' ]\n",
        "learning_rate = 0.01\n",
        "lambd = 5\n",
        "iterations = 1000\n",
        "\n",
        "# Training with normalized inputs\n",
        "normalized_train_losses_b, normalized_valid_losses_b = train(X, normalized_training, normalized_validation, y_train, y_valid, learning_rate, lambd, iterations)\n",
        "\n",
        "# Training with standardized inputs\n",
        "standardized_train_losses_b, standardized_valid_losses_b = train(X, standardized_training, standardized_validation, y_train, y_valid, learning_rate, lambd, iterations)\n",
        "\n",
        "plt.plot(normalized_train_losses_b, label=\"Training Loss\")\n",
        "plt.plot(normalized_valid_losses_b, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"3b. Loss using Normalized Inputs\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(standardized_train_losses_b, label=\"Training Loss\")\n",
        "plt.plot(standardized_valid_losses_b, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"3b. Loss using Standardized Inputs\")\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}